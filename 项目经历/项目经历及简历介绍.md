## 项目经历

### 一、Apollo项目概述

1. **总述**：

   这个项目主要将Apollo系统部署在公司的实际车辆上，调试底盘、激光雷达、相机、组合惯导等传感器，对定位、感知、规控等单元进行功能性测试，最终实现小场景内无人驾驶DEMO。我们使用pix车厂购置的汽车底盘以及相关的传感器作为硬件基础，并使用Apoll6.0这一主流的自动驾驶框架作为软件系统。

2. **系统框架**：

   给我影响最深的可能是整个自动驾驶框架，让我感觉到一个工业级或者近工业级的工程的魅力。整个系统开阔了我的眼界，除了之前有接触过的日志系统、参数系统之外，还有时钟和定时器，单元测试、线程池管理、序列化和反序列化、系统监控等。因为时间关系，其中部分没有深入了解，但是它的确是我当前阶段的学习方向；同时，从驱动、定位、感知再到routing和规划，最后到控制，使我对自动驾驶有一种全貌性的了解，比如定位就需要为感知提供定位、为规划提供定位和速度等；因为本质上这些模块都是相互依赖的，对整个工程的理解的确加深了。

3. **定位部分**：

   我主要负责定位、标定和感知部分。Apollo系统的定位系统其实很简陋，特别是最困难的多传感器融合部分还被闭源了，但是并不是说在这部分并没有什么收获。相反，通过阅读代码，包括debug，在我脑海里面建立起了一套比较清晰的时间、空间和坐标系统一框架，理解了定位遇到的各种困难：包括信号丢失、同一topic的消息到两个节点之间的顺序不一致的等情况；

   后来我们把一个完成的多传感器融合框架迁移到了Apollo上面来。我们采用的是动态库的方案，这里面牵扯非常多的东西。首先就是库的引用与封装，因为Apollo是用的bazel封装的，很多库需要自己写或者换，比如说VINS里面用的那个地理库就被我们换成了Proj.4，Sophus库被我们用自己写的类给替换掉了等等；然后原始代码和ros的耦合度比较高，需要把代码进行解耦，还需要对接口进行分离，避免过多的库依赖。收获还是蛮多的。

4. **标定部分**

   标定部分我理解在正式大公司是一个非常复杂的系统性工程，到最后需要实现标定车间的自动化标注。但是由于要求不是那么高。总的来说，我们的标定分为两部分，时钟对齐和内外参标定。

   内参参标定又分为内参标定和外参标定，内参标定包括用张正友标定相机内参，轮式里程计标定，车辆动力学标定等；外参标定包括激光和相机之间的标定（这个采用了边缘对齐的方法），还有组合惯导和激光的标定（这个先用手眼标定AX=XB获取初始，再用ICP对齐实现的）。代码实现部分其实是参考了一些开源框架和mentor自己写的程序。

   时钟对齐由于相机不是那种定制的相机，因此只考虑了激光时钟和组合惯导通过PPS脉冲信号+NMEA消息进行对齐，当激光雷达接收到PPS信号时，会去置零微秒定时器。当合法有效的GPRMC信号到来的时候，系统抽取GPRMC信号中的时间，换算成整秒，修正激光雷达整秒的时间戳

### 二、物体级别SLAM系统

当时选这个课题的时候过程也是很坎坷的，因为导师的一些原因，也是有很多折磨和妥协的。之所以选择物体级别的语义，而不是选择点云级别的语义，是因为物体其实具有天然的语义属性，它所具有的形状、朝向、大小等信息，更容易和语义地图、动态场景去除甚至后续的感知规划环节进行结合。

整个项目是建立在EAO-SLAM基础上进行的。由于这个系统其实只能算是半开源，因此我首先对这个系统进行了大量的改进：修正了很多bug，插入了基于TR的YOLOX作为在线的目标检测，增加了可视化，增加了ROS接口和可视化，增加了优化部分代码，提供基于IMU的初始化等等

在实践中逐渐发现它采用的物体估计算法并不是很准确，尤其是在机器人应用中，由于视角受限，我们只能看到物体的一部分，因此可能很难构建合适的模型。然后查了查资料，发现北航有这方面的研究，都是基于对称性来检测的。但是对称性耗时比较大。因此就想到了，既然观测不完全，能否使用退化的模型代替？于是就有了这个可进化的SLAM，用圆柱模型这种退化模型描述物体。

同时，我也测试了一些数据关联算法，这方面算法比较多，我迁移了几个算法试了试，部分算法速度比较慢，有的 需要用深度学习，比较麻烦，最后选择了bytetracker作为二维追踪器 ，配上之前的EAO那种基于统计学的方法，完成了比较准确的数据关联。

+ 缺点：圆柱其实不是一个很好的特征表示，圆柱拟合更依赖于点云获取，在室内需要深度相机的参与，然而常见的深度相机视野过于小，远远不如激光或者鱼眼相机带来的增益，因此我理想去做物体slam更多的应该关注单目+imu这种形式；此外，关于物体的位姿估计，是否深度学习方案能代替传统的位姿估计方案也是一个很值得思考的问题，我的回答是肯定会，但是受限于一些外在原因，这个方向也没法深入下去；最后，物体位姿是否用于优化，这是一个非常值得思考的问题，大部分结果显示，物体位姿对slam精度和鲁棒性提高并没有想象那么多，甚至远远不如多基元来的多。更多的物体slam中优化机器人本身位姿倒是一个副产品，而对物体位姿估计成了主要目标；从我个人来看，我更倾向于语义点云slam建图，然后后处理获得物体位姿，然后再定位部分引入物体slam，这样可能更加合理一点；